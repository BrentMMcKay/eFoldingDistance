{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to calculate and plot eFold distance of inter-site temperature correlation using the eFold module. The source data for this example is NOAA's Global Historical Climate Network Monthly temperature dataset (https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4).\n",
    "\n",
    "The source code in the notebook converts the fixed width ASCII dataset into a set of times and temperatures, then uses the eFold module to filter the dataset, calculate the correlations between sites, then calculate and plot the eFold distances between the correlations.\n",
    "\n",
    "Working with larger datasets on memory- or CPU-limited computers can be slow. There are several checkpoints in the notebook where processed data can be saved or restored via a pickle file, to reduce times of future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import system packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import cartopy\n",
    "import sys\n",
    "import io\n",
    "import warnings\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import local modules\n",
    "from eFold import binTime\n",
    "from eFold import bandPassFilter\n",
    "from eFold import binAndFilter\n",
    "from eFold import eFoldingDistance\n",
    "from eFold import calcEFold\n",
    "from eFold import plotMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input file parameters\n",
    "monthNames = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "inputDataFid = 'ghcnm.tavg.v3.3.0.20171130.qca.dat'\n",
    "inputMetafileFid = 'ghcnm.tavg.v3.3.0.20171130.qca.inv'\n",
    "inputFirstLastFid = 'ghcnm.v3.first.last.txt'\n",
    "dataTColumns = ['id','year','element','jan','dm1','qc1','ds1','feb','dm2','qc2','ds2','mar','dm3','qc3','ds3',\n",
    "                'apr','dm4','qc4','ds4','may','dm5','qc5','ds5','jun','dm6','qc6','ds6','jul','dm7','qc7','ds7',\n",
    "                'aug','dm8','qc8','ds8','sep','dm9','qc9','ds9','oct','dm10','qc10','ds10',\n",
    "                'nov','dm11','qc11','ds11','dec','dm12','qc12','ds12' ]\n",
    "dataTWidths = [ 11,4,4,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1,5,1,1,1 ]\n",
    "minimumDuration = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temperatures from input file into dataframe\n",
    "dataT = pd.read_fwf(inputDataFid,widths=dataTWidths,names=dataTColumns)\n",
    "\n",
    "# In this dataset, missing readings are represented by the value -9999,\n",
    "# so change all -9999 to NaN\n",
    "dataT = dataT.replace(-9999,np.NaN)\n",
    "dataT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Metadata from input file into dataframe\n",
    "metadataColumns = ['id','latitude','longitude','elevation','sitename',\n",
    "                 'GRELEV','POPCLS','POPSIZ','TOPO','STVEG','STLOC',\n",
    "                 'OCNDIS','AIRSTN','TOWNDIS','GRVEG','POPCSS']\n",
    "metadataWidths = [11,9,10,7,31,5,1,5,2,2,2,2,1,2,16,1]\n",
    "metadata = pd.read_fwf(inputMetafileFid,widths=metadataWidths,names=metadataColumns)\n",
    "metadata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FirstLast data into a dataframe\n",
    "firstLastColumnNames = ['id','duration']\n",
    "firstLastColspecs = [(0,11),(61,65)]\n",
    "firstLast = pd.read_fwf(inputFirstLastFid,colspecs=firstLastColspecs,names=firstLastColumnNames,skiprows=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the duration from the FirstLast DF into the metadata DF\n",
    "metadata = pd.merge(metadata,firstLast,on='id',how='left')\n",
    "\n",
    "# Filter out short durations\n",
    "goodMetadata = metadata[metadata.duration.ge(minimumDuration)]\n",
    "goodMetadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a list containing one dictionary for each site\n",
    "# Each site dictionary will contain metadata:latitude, longitude, elevation, sitename, and oceanDist, \n",
    "# along with a dataframe of monthly temperatures\n",
    "#\n",
    "siteList = []\n",
    "\n",
    "\n",
    "# FOR TESTING USING A SMALLER DATASET, modify this values to use only every nth datasite.\n",
    "useNthSite = 1\n",
    "\n",
    "#iterate over all the sites\n",
    "for index,site in goodMetadata.iterrows():\n",
    "    if index % useNthSite != 0:\n",
    "        continue\n",
    "    siteDict = {}\n",
    "    siteDict['latitude'] = site['latitude']\n",
    "    siteDict['longitude'] = site['longitude']\n",
    "    siteDict['sitename'] = site['sitename']\n",
    "\n",
    "    #select the temperature data for this site only\n",
    "    siteT = dataT[dataT['id']==site['id']]\n",
    "\n",
    "    # Pull out all the monthly temperatures, and divide by 100 (convert units from millidegrees to degrees)\n",
    "    monthlyT = siteT[monthNames]/100.0\n",
    "\n",
    "    # Add the years field into the dataframe\n",
    "    years = siteT['year']\n",
    "\n",
    "    # Create array of monthly differences from the mean\n",
    "    valsArray = np.array(monthlyT.loc[:,'jan':'dec'])\n",
    "\n",
    "    # Create matching array of the year/month for each value\n",
    "    months = np.tile(np.arange(1/24,1.0,1/12),(len(years),1))\n",
    "    years = np.tile(years,(12,1)).transpose()\n",
    "    timeArray = months+years\n",
    "\n",
    "    siteDict['temps'] = np.array(monthlyT).flatten()\n",
    "    siteDict['times'] = timeArray.flatten()\n",
    "\n",
    "    siteList.append(siteDict)\n",
    "\n",
    "len(siteList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following to save the siteList for later\n",
    "\n",
    "#outPickleFid='ipynb.sitelist.GHCN.pickle.dat'\n",
    "#pickle.dump(siteList, open(outPickleFid,'wb'))\n",
    "\n",
    "# If running with previously loaded data, uncomment and run:\n",
    "\n",
    "#pickleFidIn = 'ipynb.sitelist.GHCN.pickle.dat'\n",
    "#siteList = pickle.load(open(pickleFidIn,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin all the temperatures into years, and filter out the low frequency repetitions\n",
    "pickleFidOut = 'ipynb.filtered.GHCN.pickle.dat'\n",
    "filteredArray = binAndFilter( siteList, timeStart=1900,timeEnd=2011,timeStep=1,highBandPass=True,replaceNaN=True,replaceNaNDivisor=12,outFid=pickleFidOut )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations between each pair of sites and the eFold distance for each site\n",
    "eFold = calcEFold( siteList, filteredArray )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data on a map\n",
    "# Put the data into usable lists                     \n",
    "lons = []                                            \n",
    "lats = []                                            \n",
    "r2 = []                                              \n",
    "eFoldDistance = []                                   \n",
    "for i in range(0,len(eFold)):                        \n",
    "    lons.append(eFold[i]['lon'])                     \n",
    "    lats.append(eFold[i]['lat'])\n",
    "    r2.append(eFold[i]['r2'])\n",
    "    eFoldDistance.append(eFold[i]['eFoldDistance'])\n",
    "\n",
    "plt.rcParams['figure.figsize']=[10,5]\n",
    "plotMap( lats, lons, eFoldDistance,plotTitle='GHCN40',dataLabel='e-Folding Distance (km)' )\n",
    "plotMap( lats, lons,r2,plotTitle='GHCN40',dataLabel='$r^2$ for eFoldDistance',dotSize=10)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
